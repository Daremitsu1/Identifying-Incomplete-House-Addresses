{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e78f1b60",
   "metadata": {},
   "source": [
    "### Identifying country names from incomplete house addresses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a290cf1",
   "metadata": {},
   "source": [
    "#### 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61e99641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd \n",
    "from pathlib import Path \n",
    "from arcgis.gis import GIS\n",
    "from arcgis.learn import prepare_textdata \n",
    "from arcgis.learn.text import TextClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c7347f",
   "metadata": {},
   "source": [
    "#### 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f630e46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'country_classifier.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3804c9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(filepath, 'r') as zip_ref:\n",
    "    zip_ref.extractall(Path(filepath).parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77d22bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(os.path.join(os.path.splitext(filepath)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d36c4849",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aviparna.biswas\\Anaconda3\\envs\\docuchief\\lib\\site-packages\\arcgis\\learn\\models\\_arcgis_model.py:450: UserWarning: Cuda is not available\n",
      "  warnings.warn(\"Cuda is not available\")\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Traceback (most recent call last):\n\n  File \"C:\\Users\\aviparna.biswas\\Anaconda3\\envs\\docuchief\\lib\\site-packages\\arcgis\\learn\\_utils\\text_data.py\", line 32, in <module>\n    from .text_transforms import (\n\n  File \"C:\\Users\\aviparna.biswas\\Anaconda3\\envs\\docuchief\\lib\\site-packages\\arcgis\\learn\\_utils\\text_transforms.py\", line 68, in <module>\n    class TransformersBaseTokenizer(BaseTokenizer):\n\n  File \"C:\\Users\\aviparna.biswas\\Anaconda3\\envs\\docuchief\\lib\\site-packages\\arcgis\\learn\\_utils\\text_transforms.py\", line 77, in TransformersBaseTokenizer\n    seq_len=512,\n\nNameError: name 'PreTrainedTokenizer' is not defined\n\n\nThis module requires fastai, PyTorch and transformers as its dependencies.\nInstall them using - 'conda install -c esri -c fastai -c pytorch arcgis=1.8.2 scikit-image=0.15.0 pillow=6.2.2 libtiff=4.0.10 fastai=1.0.60 pytorch=1.4.0 torchvision=0.5.0 scikit-learn=0.23.1 --no-pin'\n'conda install gdal=2.3.3'\n'pip install transformers==3.3.0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-061851a84f07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m data = prepare_textdata(DATA_ROOT, \"classification\", train_file=\"house-addresses.csv\", \n\u001b[1;32m----> 2\u001b[1;33m                         text_columns=\"Address\", label_columns=\"Country\", batch_size=64)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\docuchief\\lib\\site-packages\\arcgis\\learn\\_data.py\u001b[0m in \u001b[0;36mprepare_textdata\u001b[1;34m(path, task, text_columns, label_columns, train_file, valid_file, val_split_pct, seed, batch_size, process_labels, remove_html_tags, remove_urls, working_dir, **kwargs)\u001b[0m\n\u001b[0;32m    837\u001b[0m             \u001b[0mremove_html_tags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mremove_html_tags\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    838\u001b[0m             \u001b[0mremove_urls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mremove_urls\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 839\u001b[1;33m             \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    840\u001b[0m         )\n\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\docuchief\\lib\\site-packages\\arcgis\\learn\\_utils\\text_data.py\u001b[0m in \u001b[0;36mprepare_data_for_classification\u001b[1;34m(cls, data, text_cols, label_cols, train_file, valid_file, val_split_pct, seed, batch_size, process_labels, remove_html_tags, remove_urls, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m     ):\n\u001b[0;32m    280\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mHAS_FASTAI\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m             \u001b[0m_raise_fastai_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimport_exception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[0mtext_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"classification\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\docuchief\\lib\\site-packages\\arcgis\\learn\\_utils\\text_data.py\u001b[0m in \u001b[0;36m_raise_fastai_exception\u001b[1;34m(exception)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;34m\"\\n'pip install transformers==3.3.0'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     )\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Traceback (most recent call last):\n\n  File \"C:\\Users\\aviparna.biswas\\Anaconda3\\envs\\docuchief\\lib\\site-packages\\arcgis\\learn\\_utils\\text_data.py\", line 32, in <module>\n    from .text_transforms import (\n\n  File \"C:\\Users\\aviparna.biswas\\Anaconda3\\envs\\docuchief\\lib\\site-packages\\arcgis\\learn\\_utils\\text_transforms.py\", line 68, in <module>\n    class TransformersBaseTokenizer(BaseTokenizer):\n\n  File \"C:\\Users\\aviparna.biswas\\Anaconda3\\envs\\docuchief\\lib\\site-packages\\arcgis\\learn\\_utils\\text_transforms.py\", line 77, in TransformersBaseTokenizer\n    seq_len=512,\n\nNameError: name 'PreTrainedTokenizer' is not defined\n\n\nThis module requires fastai, PyTorch and transformers as its dependencies.\nInstall them using - 'conda install -c esri -c fastai -c pytorch arcgis=1.8.2 scikit-image=0.15.0 pillow=6.2.2 libtiff=4.0.10 fastai=1.0.60 pytorch=1.4.0 torchvision=0.5.0 scikit-learn=0.23.1 --no-pin'\n'conda install gdal=2.3.3'\n'pip install transformers==3.3.0'"
     ]
    }
   ],
   "source": [
    "data = prepare_textdata(DATA_ROOT, \"classification\", train_file=\"house-addresses.csv\", \n",
    "                        text_columns=\"Address\", label_columns=\"Country\", batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4067f5fd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-9ccb24ee9b8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "print(data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9be0063",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4595f85a",
   "metadata": {},
   "source": [
    "### 3. TextClassifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51d8358c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BERT', 'RoBERTa', 'DistilBERT', 'ALBERT', 'FlauBERT', 'CamemBERT', 'XLNet', 'XLM', 'XLM-RoBERTa', 'Bart', 'ELECTRA', 'Longformer', 'MobileBERT', 'Funnel']\n"
     ]
    }
   ],
   "source": [
    "print(TextClassifier.supported_backbones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ca45c0c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Traceback (most recent call last):\n\n  File \"C:\\Users\\aviparna.biswas\\Anaconda3\\envs\\docuchief\\lib\\site-packages\\arcgis\\learn\\text\\_text_classifier.py\", line 23, in <module>\n    from transformers import AutoTokenizer, AutoConfig\n\n  File \"C:\\Users\\aviparna.biswas\\Anaconda3\\envs\\docuchief\\lib\\site-packages\\transformers\\__init__.py\", line 124, in <module>\n    from .pipelines import (\n\n  File \"C:\\Users\\aviparna.biswas\\Anaconda3\\envs\\docuchief\\lib\\site-packages\\transformers\\pipelines.py\", line 47, in <module>\n    from .modeling_tf_auto import (\n\n  File \"C:\\Users\\aviparna.biswas\\Anaconda3\\envs\\docuchief\\lib\\site-packages\\transformers\\modeling_tf_auto.py\", line 45, in <module>\n    from .modeling_tf_albert import (\n\n  File \"C:\\Users\\aviparna.biswas\\Anaconda3\\envs\\docuchief\\lib\\site-packages\\transformers\\modeling_tf_albert.py\", line 43, in <module>\n    from .modeling_tf_utils import (\n\n  File \"C:\\Users\\aviparna.biswas\\Anaconda3\\envs\\docuchief\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 23, in <module>\n    import h5py\n\n  File \"C:\\Users\\aviparna.biswas\\Anaconda3\\envs\\docuchief\\lib\\site-packages\\h5py\\__init__.py\", line 33, in <module>\n    from . import version\n\n  File \"C:\\Users\\aviparna.biswas\\Anaconda3\\envs\\docuchief\\lib\\site-packages\\h5py\\version.py\", line 15, in <module>\n    from . import h5 as _h5\n\n  File \"h5py\\h5.pyx\", line 1, in init h5py.h5\n\nImportError: DLL load failed: The specified procedure could not be found.\n \n\nDeep learning dependencies are missing. This module requires fastai, PyTorch, torchvision. \n\nPlease install all required dependencies by following the instructions at: \nhttps://developers.arcgis.com/python/guide/install-and-set-up/#Install-deep-learning-dependencies\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-144ab53689c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTextClassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavailable_backbone_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"xlm-roberta\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\docuchief\\lib\\site-packages\\arcgis\\learn\\text\\_text_classifier.py\u001b[0m in \u001b[0;36mavailable_backbone_models\u001b[1;34m(cls, architecture)\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_raise_fastai_import_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m             \u001b[0m_raise_fastai_import_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimport_exception\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimport_exception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mTransformerForTextClassification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_available_backbone_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marchitecture\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\docuchief\\lib\\site-packages\\arcgis\\learn\\_data.py\u001b[0m in \u001b[0;36m_raise_fastai_import_error\u001b[1;34m(import_exception)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[0minstallation_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_installation_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m     raise Exception(\n\u001b[1;32m--> 139\u001b[1;33m         \u001b[1;34mf\"{import_exception} \\n\\nDeep learning dependencies are missing. This module requires fastai, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;34mf\"PyTorch, torchvision. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[1;34mf\"\\n{installation_steps}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Traceback (most recent call last):\n\n  File \"C:\\Users\\aviparna.biswas\\Anaconda3\\envs\\docuchief\\lib\\site-packages\\arcgis\\learn\\text\\_text_classifier.py\", line 23, in <module>\n    from transformers import AutoTokenizer, AutoConfig\n\n  File \"C:\\Users\\aviparna.biswas\\Anaconda3\\envs\\docuchief\\lib\\site-packages\\transformers\\__init__.py\", line 124, in <module>\n    from .pipelines import (\n\n  File \"C:\\Users\\aviparna.biswas\\Anaconda3\\envs\\docuchief\\lib\\site-packages\\transformers\\pipelines.py\", line 47, in <module>\n    from .modeling_tf_auto import (\n\n  File \"C:\\Users\\aviparna.biswas\\Anaconda3\\envs\\docuchief\\lib\\site-packages\\transformers\\modeling_tf_auto.py\", line 45, in <module>\n    from .modeling_tf_albert import (\n\n  File \"C:\\Users\\aviparna.biswas\\Anaconda3\\envs\\docuchief\\lib\\site-packages\\transformers\\modeling_tf_albert.py\", line 43, in <module>\n    from .modeling_tf_utils import (\n\n  File \"C:\\Users\\aviparna.biswas\\Anaconda3\\envs\\docuchief\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 23, in <module>\n    import h5py\n\n  File \"C:\\Users\\aviparna.biswas\\Anaconda3\\envs\\docuchief\\lib\\site-packages\\h5py\\__init__.py\", line 33, in <module>\n    from . import version\n\n  File \"C:\\Users\\aviparna.biswas\\Anaconda3\\envs\\docuchief\\lib\\site-packages\\h5py\\version.py\", line 15, in <module>\n    from . import h5 as _h5\n\n  File \"h5py\\h5.pyx\", line 1, in init h5py.h5\n\nImportError: DLL load failed: The specified procedure could not be found.\n \n\nDeep learning dependencies are missing. This module requires fastai, PyTorch, torchvision. \n\nPlease install all required dependencies by following the instructions at: \nhttps://developers.arcgis.com/python/guide/install-and-set-up/#Install-deep-learning-dependencies\n"
     ]
    }
   ],
   "source": [
    "print(TextClassifier.available_backbone_models(\"xlm-roberta\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503d7295",
   "metadata": {},
   "source": [
    "### 4. Load Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451e00ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextClassifier(data, backbone=\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404b8270",
   "metadata": {},
   "source": [
    "### 5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f898f611",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5037940",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(epochs=4, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef74be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze earlier layers to further fine-tune the model\n",
    "model.unfreeze()\n",
    "\n",
    "model.fit(epochs=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c24342",
   "metadata": {},
   "source": [
    "### 6. Validate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092b83dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training, checking the results to see how it performs\n",
    "model.show_results(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e6cbcf",
   "metadata": {},
   "source": [
    "### 7. Test the model prediction on an input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603c9c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"1016, 8A, CL RICARDO LEON - SANTA ANA (CARTAGENA), 30319\"\"\"\n",
    "print(model.predict(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486e538a",
   "metadata": {},
   "source": [
    "### 8. Model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcf3f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see how accurate the model is in correctly predicting the classes in the dataset\n",
    "model.accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0513ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also check precision, recall & f1 scores per label/class\n",
    "model.metrics_per_label()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f51dd3f",
   "metadata": {},
   "source": [
    "### 9. Get misclassified records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f88513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the misclassified records we will call the model's get_misclassified_records method\n",
    "misclassified_records = model.get_misclassified_records()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a41e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified_records.style.set_table_styles([dict(selector='th', props=[('text-align', 'left')])])\\\n",
    "        .set_properties(**{'text-align': \"left\"}).hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a389c7d",
   "metadata": {},
   "source": [
    "### 10. Saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cbaea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model for interfencing on unseen data\n",
    "model.save(\"country_classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2614de",
   "metadata": {},
   "source": [
    "### 11. Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84f9c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the trained model to classify new text documents using the predict method\n",
    "text_list = data._train_df.sample(15).Address.values\n",
    "result = model.predict(text_list)\n",
    "\n",
    "df = pd.DataFrame(result, columns=[\"Address\", \"CountryCode\", \"Confidence\"])\n",
    "\n",
    "df.style.set_table_styles([dict(selector='th', props=[('text-align', 'left')])])\\\n",
    "        .set_properties(**{'text-align': \"left\"}).hide_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docuchief",
   "language": "python",
   "name": "docuchief"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
